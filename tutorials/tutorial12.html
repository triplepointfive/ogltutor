<!DOCTYPE html><html><head><meta content="IE=edge" http-equiv="X-UA-Compatible" /><meta charset="utf-8" /><meta content="width=device-width,initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no" name="viewport" /><meta content="" name="keywords" /><meta content="" name="description" /><title>Уроки по OpenGL с сайта OGLDev - Урок 12 - Проекция перспективы</title><link href="//fonts.googleapis.com/css?family=Lato:300,400" rel="stylesheet" type="text/css" /><script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script><link href="../stylesheets/site.css" rel="stylesheet" media="all" type="text/css" /><script src="../javascripts/shCore.js"></script><script src="../javascripts/shBrushCpp.js"></script><script src="../javascripts/all.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-35259428-1', 'auto');
ga('send', 'pageview');</script></head><body><div class="row header"><div class="large-12 columns"><div class="nav-bar right"><ul class="button-group"><li><a href="../" class="button nav-left">Содержание</a></li><li><a href="../instr.html" class="button">Инструкции</a></li><li><a href="../cont.html" class="button nav-right">Контакты</a></li></ul></div><h1><small>Уроки по OpenGL с сайта OGLDev</small></h1><hr /></div></div><div class="row"><div class="large-12 columns"><div class="tutorial"><h2><a href="http://ogldev.atspace.co.uk/www/tutorial12/tutorial12.html">Урок 12 - Проекция перспективы</a></h2><p>Наконец мы добрались до пункта, характеризующего 3D графику лучше всего, - проекция из 3D мира на 2D плоскость, сохраняя при этом глубину. Хорошим примером будет изображение железной дороги, которая уходя в даль становится одной точкой.</p>

<p>Мы собираемся найти преобразование, удовлетворяющее требованиям выше и у нас еще одно дополнительное условие: мы хотим представить его "ярусным", и что бы у клипера жизнь была проще, требуется переводить координаты в пространство экрана от -1 до +1. Это значит, что клипер будет делать свою работу не заботясь о пространстве экрана и расположения ближнего и дальнего рубежей.</p>

<p>Проекция перспективы будет принимать от нас 4 параметра:</p>

<ol>
  <li>Соотношение сторон - коэффициент между шириной и высотой прямоугольной области, на которую и будет осуществляться проекция.</li>
  <li>Поле зрения по вертикали: угол обзора камеры, через который мы видим мир.</li>
  <li>Позиция ближней Z плоскости. Позволяет нам обрезать объекты, находящиеся слишком близко к камере.</li>
  <li>Позиция дальней Z плоскости. Позволяет нам обрезать объекты, находящиеся слишком далеко от камеры.</li>
</ol>

<p>Соотношение сторон становится необходимым из того, что мы собираемся представить все координаты в нормированном пространстве, ширина которого равна его высоте. Так как такая ситуация у мониторов довольно редкая, обычно ширина больше чем высота, нам необходимо как-то "конденсировать" точки на горизонтальной линии по сравнению с вертикальной. Это позволит нам выжать больше точек по X компоненте в нормированном пространстве, что в итоге позволит в итоге "видеть" больше по ширине, чем по высоте.</p>

<p>Вертикальное поле зрения позволит нам увеличивать и уменьшать мир. Рассмотрим следующий пример. На картинке слева угол обзора больше, что делает объекты меньше, а на изображении справа угол меньше, что увеличивает объект. Заметьте, что это влияет на расположение камеры, делая ее немного более интуитивной. Справа (где мы увеличиваем с малым углом обзора) камере требуется быть дальше, и на левой стороне она ближе к плоскости проекции. Хотя, вспомним, что нет никакой разницы, ведь мы преобразуем координаты проекции в экран, поэтому позиция камеры не играет роли.</p>

<p><img src="../images/t12_FOV.png" alt="" /></p>

<p>Начнем мы с определения расстояния плоскости проекции до камеры. Эта плоскость будет параллельна плоскости XY. Очевидно, видна будет не вся плоскость из-за ее огромных размеров. Мы сможем увидеть вещи из прямоугольной области (называемой окном проекции), которая имеет те же пропорции, что и наш экран. Соотношение сторон подсчитывается так:</p>

<p>ar = ширина экрана / высота экрана</p>

<p>Давайте для удобства выберем высоту в 2 раза меньше ширины, тогда соотношение сторон будет равно 2 (по формуле выше). Если мы поместим камеру в начало координат и посмотрим на область с точки зрения камеры, мы увидим:</p>

<p><img src="../images/t12_projection_window.png" alt="" /></p>

<p>Все, что выходит за пределы этого прямоугольника, будет обрезано и мы видим, что координаты внутри будут иметь Y компоненту в требуемом отрезке. Но X координата пока что немного больше, но мы это исправим позднее.</p>

<p>Теперь посмотрите на это сбоку (на плоскости YZ):</p>

<p><img src="../images/t12_side_view1.png" alt="" /></p>

<p>Мы найдем расстояние от камеры до плоскости проекции используя высоту обзора по вертикали (обозначается углом альфа):</p>

<p><img src="../images/t12_12_01.png" alt="" /></p>

<p>Следующий шаг - это подсчет проецированных координат X и Y. Рассмотрим следующее изображение (смотрим на плоскость YZ).</p>

<p><img src="../images/t12_side_view2.png" alt="" /></p>

<p>У нас есть точка в 3D пространстве с координатами (x,y,z). Мы хотим найти (x<sub>p</sub>,y<sub>p</sub>), которые преобразуют проецированные координаты на плоскость проекции. Так как X компонента не видна на этой схеме, то мы начнем с Y. Согласно правилу подобных треугольников, мы получаем следующее:</p>

<p><img src="../images/t12_12_02.png" alt="" /></p>

<p>И то же самое для X координаты:</p>

<p><img src="../images/t12_12_03.png" alt="" /></p>

<p>Так как размер нашего окна проекции равен 2*ar (ширина на 2 высоты), мы знаем, что точка в 3D пространстве внутри нашего окна, если она проецируется в точку, координата X которой в пределах от -ar и до +ar, и проецированная Y координата между -1 и +1. Поэтому Y компонента нормирована, но X еще нет. Мы можем нормировать Xp просто поделив на соотношение сторон. Это означает, что точка, имевшая X равным +ar теперь имеет равным +1, что расположит её на правой стороне экрана. Если X был равным +0.5 и стороны соотносятся как 1.333 (такое например у экрана с разрешением 1024x768), новая координата X равна 0.375. Подводя итоги, деление на соотношение сторон позволяет конденсировать точки по оси X.</p>

<p>Итак, мы имеем следующие выражения для X и Y:</p>

<p><img src="../images/t12_12_04.png" alt="" /></p>

<p>Прежде чем завершить процесс, давайте рассмотрим матрицу проекции на данный момент. Это значит, что преобразования выше должны быть представлены в виде матрицы. Теперь рассмотрим задачу. В обоих выражениях нам необходимо разделить X и Y на Z, который является элементом в векторе позиции. Но значение Z меняется от вершины к вершине, поэтому нельзя поместить его в матрицу, проходящую все вершины. Что бы понять это лучше, подумайте о ряде матриц (a, b, c, d). Теперь нам необходимо получить значение вектора, для которого будет справедливо следующее:</p>

<p><img src="../images/t12_12_05.png" alt="" /></p>

<p>Это скалярное произведение между верхним вектором матрицы с вектором позиции, который дает итоговое значение X координаты. Мы можем выбрать 'b' и 'd' равными 0, но мы не можем найти 'a' и 'c', которые необходимы слева, а получены могут быть только справа. Решение принятое OpenGL - это разделение преобразований на 2 этапа: умножение на матрицу проекции следует за делением на значение Z как отдельный шаг. Матрица предоставляется приложением и шейдер должен включать умножение ее на позицию. Деление на Z жестко задано в GPU и принимает участие в растеризаторе (где-то между вершинным и фрагментным шейдерах). Как GPU узнает какую вершину, выпущенную вершинным шейдером делить на ее Z значение? просто - встроенная переменная gl_Position продумана для этой работы. Теперь осталось только найти матрицу, которая будет подсчитывать проецированные значения для X и Y.</p>

<p>После умножения на эту матрицу GPU может поделить на Z для нас автоматически, и мы получим тот результат, который хотели. Но есть еще одна сложность: если мы умножим матрицу на вектор позиции, а затем поделим на Z, то мы потеряем Z координату, потому, что для всех вершин она станет равна 1. Настоящее значение Z должно быть сохранено для дальнейшего теста глубины. Трюк в том, что мы записываем исходное значение Z в компоненту W итогового вектора и делим только XYZ на W вместо Z. W сохранит исходное значение Z, которое может быть использовано для теста глубины. Автоматическое деление gl_Position на его W и называется делением перспективы.</p>

<p>Мы можем теперь генерировать промежуточную матрицу, которая заменит 2 формулы выше, а так же перенесет Z в W элемент:</p>

<p><img src="../images/t12_12_06.png" alt="" /></p>

<p>Как я говорил ранее, мы хотим нормировать значение Z, что бы облегчить работу клиперу, что бы он не задумывался об ближнем и дальнем значениях Z. Хотя матрица выше обратит Z в 0. Зная то, что после преобразования вектора система сама автоматически найдет перспективу, нам необходимо выбрать значения для третьей строки матрицы, что бы любое значение  Z из промежутка (т.е. NearZ &lt;= Z &lt;= FarZ) было отображено в отрезок [-1,1]. Такое отображение состоит из 2 этапов. В первом мы уменьшаем отрезок [NearZ, FarZ], пока его длина не будет равна 2. Затем сдвигаем так, что бы начало совпадало с -1. Уменьшение Z значения и его перемещение заменяется общей функцией:</p>

<p><img src="../images/t12_12_07.png" alt="" /></p>

<p>Но следующее деление с правой стороны функции:</p>

<p><img src="../images/t12_12_08.png" alt="" /></p>

<p>Теперь нам надо найти значения A и B, которые после будут перенесены в [-1,1]. Мы знаем, что когда Z соответствует NearZ, итог будет -1, и когда Z соответствует FarZ результат будет равен 1. Это можно записать так:</p>

<p><img src="../images/t12_12_09.png" alt="" /></p>

<p>Теперь нам необходимо выбрать третью строку матрицы как вектор (a b c d), который будет удовлетворять:</p>

<p><img src="../images/t12_12_10.png" alt="" /></p>

<p>Мы можем выбрать 'a' и 'b' равными 0, поскольку мы не хотим, что бы X и Y влияли на преобразование Z. Тогда A может стать равным 'c', а B равным 'd' (так как нам известно, что W равен 1).</p>

<p>Итак, конечная матрица преобразований такова:</p>

<p><img src="../images/t12_12_11.png" alt="" /></p>

<p>После умножения вектора позиции на матрицу проекции координаты будут в пространстве клипера (<em>Clip Space</em>), и после деления перспективы координаты в нормированном пространстве (<em>NDC Space</em> (Normalized Device Coordinates)).</p>

<p>Путь, который мы проделали в этой серии уроков, теперь должен быть ясным и понятным. Без какого-либо проецирования мы можем запросто получить вершины из вершинного шейдера, координаты XYZ которых не будут находится в промежутке [-1,+1]. А так мы уверены, что они в пространстве экрана. Назначив W всегда равной 1 мы просто защищаемся от каких-либо эффектов деления перспективы. Мы заканчиваем после того, как координаты перемещены в пространство экрана. Когда мы используем матрицу проекции, деление перспективы всего лишь внутренний этап проекции из 3D в 2D.</p>

<h2 id="httpsgithubcomtriplepointfiveogldevtreemastertutorial12"><a href="https://github.com/triplepointfive/ogldev/tree/master/tutorial12">Прямиком к коду!</a></h2>

<pre><code>void Pipeline::InitPerspectiveProj(Matrix4f&amp; m) const&gt;
{
    const float ar = m_persProj.Width / m_persProj.Height;
    const float zNear = m_persProj.zNear;
    const float zFar = m_persProj.zFar;
    const float zRange = zNear - zFar;
    const float tanHalfFOV = tanf(ToRadian(m_persProj.FOV / 2.0));

    m.m[0][0] = 1.0f / (tanHalfFOV * ar);
    m.m[0][1] = 0.0f;
    m.m[0][2] = 0.0f;
    m.m[0][3] = 0.0f;

    m.m[1][0] = 0.0f;
    m.m[1][1] = 1.0f / tanHalfFOV;
    m.m[1][2] = 0.0f;
    m.m[1][3] = 0.0f;

    m.m[2][0] = 0.0f;
    m.m[2][1] = 0.0f;
    m.m[2][2] = (-zNear - zFar) / zRange;
    m.m[2][3] = 2.0f * zFar * zNear / zRange;

    m.m[3][0] = 0.0f;
    m.m[3][1] = 0.0f;
    m.m[3][2] = 1.0f;
    m.m[3][3] = 0.0f;
}
</code></pre>

<p>Структура, названная m_persProj, была добавлена в класс Pipeline и содержит параметры для проецирования перспективы. Метод выше генерирует матрицу, которая была разработана в теоретической секции.</p>

<pre><code>m_transformation = PersProjTrans * TranslationTrans * RotateTrans * ScaleTrans;
</code></pre>

<p>Мы ставим матрицу перспективы первой в череде умножения матриц, которые генерирует итоговое преобразование. Вспомним, что вектор позиции умножается с правой стороны от итоговой матрицы. Поэтому сначала масштабируем, затем вращаем, перемещаем и наконец проецируем.</p>

<pre><code>p.SetPerspectiveProj(30.0f, WINDOW_WIDTH, WINDOW_HEIGHT, 1.0f, 1000.0f);
</code></pre>

<p>В функции рендера мы назначаем параметры проекции. Попробуйте их изменить и посмотрите на результат.</p>
</div><div id="disqus_thread"></div><script>/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = 'ogltutor'; // required: replace example with your forum shortname
var num = "12";

var disqus_config = function () {
  this.page.url = "https://triplepointfive.github.io/ogltutor/tutorials/tutorial" + num + ".html";
  this.page.identifier = num;
  this.page.title = "Урок 12 - Проекция перспективы";
};

/* * * DON'T EDIT BELOW THIS LINE * * */
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><noscript><Please>enable JavaScript to view the</Please><a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a class="dsq-brlink" href="http://disqus.com"><comments>powered by</comments><span class="logo-disqus">Disqus</span></a></div></div><footer class="row"><div class="large-12 columns text-right"><hr />Шедевр, созданный с помощью <a href="https://middlemanapp.com/">Middleman</a><br /><small><a href="https://github.com/triplepointfive/ogltutor">Исходный код</a></small></div></footer></body></html>